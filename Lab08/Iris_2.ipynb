{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## ‚öôÔ∏è **Basic Steps to Build a Neural Network (Using iris.csv)**\n",
    "\n",
    "---"
   ],
   "id": "8fab2ca8eaf84072"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **1Ô∏è‚É£ Import Libraries**\n",
   "id": "589cec2979658fb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T09:27:39.134054Z",
     "start_time": "2025-11-25T09:27:39.017380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import numpy as np"
   ],
   "id": "78c40fdd34a43812",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "### **2Ô∏è‚É£ Prepare the Data**\n",
    "\n",
    "We assume the CSV file looks like this (standard Iris format):\n",
    "\n",
    "| sepal_length | sepal_width | petal_length | petal_width | species    |\n",
    "| ------------ | ----------- | ------------ | ----------- | ---------- |\n",
    "| 5.1          | 3.5         | 1.4          | 0.2         | setosa     |\n",
    "| 7.0          | 3.2         | 4.7          | 1.4         | versicolor |\n",
    "| 6.3          | 3.3         | 6.0          | 2.5         | virginica  |\n",
    "\n",
    "üìÅ **File name:** `iris.csv`\n",
    "\n",
    "Now, load and preprocess it:"
   ],
   "id": "20787f535045255b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T09:27:42.655844Z",
     "start_time": "2025-11-25T09:27:42.608031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load CSV file\n",
    "df = pd.read_csv('../Data/iris.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ],
   "id": "e3eed94343a68d4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Id  Sepal Length (cm)  Sepal Width (cm)  Petal Length (cm)  \\\n",
       "0   1                5.1               3.5                1.4   \n",
       "1   2                4.9               3.0                1.4   \n",
       "2   3                4.7               3.2                1.3   \n",
       "3   4                4.6               3.1                1.5   \n",
       "4   5                5.0               3.6                1.4   \n",
       "\n",
       "   Petal Width (cm)      Species  \n",
       "0               0.2  Iris-setosa  \n",
       "1               0.2  Iris-setosa  \n",
       "2               0.2  Iris-setosa  \n",
       "3               0.2  Iris-setosa  \n",
       "4               0.2  Iris-setosa  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Sepal Length (cm)</th>\n",
       "      <th>Sepal Width (cm)</th>\n",
       "      <th>Petal Length (cm)</th>\n",
       "      <th>Petal Width (cm)</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T09:27:46.217066Z",
     "start_time": "2025-11-25T09:27:46.199875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Separate features and labels\n",
    "# X = df.iloc[:, 1:-1].values  # all columns except the first and the last\n",
    "# y = df.iloc[:, -1].values  # last column (species)\n",
    "\n",
    "# Split features (X) and target (y)\n",
    "X = df.drop(['Id', 'Species'], axis=1)\n",
    "y = df['Species']\n",
    "y"
   ],
   "id": "1ee9bcfc4d927d94",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Iris-setosa\n",
       "1         Iris-setosa\n",
       "2         Iris-setosa\n",
       "3         Iris-setosa\n",
       "4         Iris-setosa\n",
       "            ...      \n",
       "145    Iris-virginica\n",
       "146    Iris-virginica\n",
       "147    Iris-virginica\n",
       "148    Iris-virginica\n",
       "149    Iris-virginica\n",
       "Name: Species, Length: 150, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "* `LabelEncoder` is a class from `sklearn.preprocessing` that converts categorical labels (text) into numeric codes.",
   "id": "1f0a66e9ca5dccce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T09:27:54.302035Z",
     "start_time": "2025-11-25T09:27:54.293380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Encode text labels (setosa, versicolor, virginica ‚Üí 0,1,2)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "y_encoded"
   ],
   "id": "d30d75e226e6071f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:23:04.018444Z",
     "start_time": "2025-11-10T12:23:04.008730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# One-hot encode target\n",
    "y_onehot = tf.keras.utils.to_categorical(y_encoded)\n",
    "y_onehot\n"
   ],
   "id": "ecc2ebe606b32155",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T14:16:18.328455Z",
     "start_time": "2025-11-10T14:16:18.274196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_onehot, test_size=0.2, random_state=42\n",
    ")"
   ],
   "id": "40f4e5365e27a99e",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### **3Ô∏è‚É£ Build the Model**\n",
    "\n",
    "A\n",
    "small\n",
    "dense\n",
    "network\n",
    "for 3 -class classification:\n"
   ],
   "id": "fac1d106588e044e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T14:22:18.114812Z",
     "start_time": "2025-11-10T14:22:18.086603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=[4]),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "# model.weights"
   ],
   "id": "dd39b50d6aeec8b",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T11:52:51.709968Z",
     "start_time": "2025-11-10T11:52:51.704006Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### **4Ô∏è‚É£ Compile the Model**\n"
   ],
   "id": "f05d1c49ab763b7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T19:03:58.133664Z",
     "start_time": "2025-11-10T19:03:58.102129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# For **multi-class classification** ‚Üí use **Categorical Cross-Entropy** (with softmax)"
   ],
   "id": "52e1834d669a1879",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T16:22:38.440910Z",
     "start_time": "2025-11-10T16:22:38.420261Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### **5Ô∏è‚É£ Train the Model**\n"
   ],
   "id": "2775dddc9f9225fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T19:09:32.008087Z",
     "start_time": "2025-11-10T19:09:31.481828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=8,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# print(\"Final training loss:\", history.history['loss'][-1])\n",
    "# print(\"Final validation loss:\", history.history['val_loss'][-1])\n",
    "# print(\"Final training accuracy:\", history.history['accuracy'][-1])\n",
    "# print(\"Final validation accuracy:\", history.history['val_accuracy'][-1])"
   ],
   "id": "73d64a48239cb510",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 - 0s - 14ms/step - accuracy: 0.9792 - loss: 0.0485 - val_accuracy: 0.9583 - val_loss: 0.1685\n",
      "Epoch 2/50\n",
      "12/12 - 0s - 12ms/step - accuracy: 0.9792 - loss: 0.0465 - val_accuracy: 0.9583 - val_loss: 0.1769\n",
      "Epoch 3/50\n",
      "12/12 - 0s - 11ms/step - accuracy: 0.9792 - loss: 0.0477 - val_accuracy: 0.9583 - val_loss: 0.1772\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### **6Ô∏è‚É£ Evaluate & Make Predictions**\n"
   ],
   "id": "16e3cd7de0e6e131"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T19:21:55.125540Z",
     "start_time": "2025-11-10T19:21:54.677642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"\\n‚úÖ Test Accuracy: {test_acc:.3f}\")\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(X_test)\n",
    "print(predictions[:5])\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "actual_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"\\nPredicted Classes:\", predicted_classes[:10])\n",
    "print(\"Actual Classes:   \", actual_classes[:10])"
   ],
   "id": "f0751f98727c9aa4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 249ms/step - accuracy: 1.0000 - loss: 0.0313\n",
      "\n",
      "‚úÖ Test Accuracy: 1.000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 74ms/step\n",
      "[[4.5683166e-05 9.9913377e-01 8.2058791e-04]\n",
      " [9.9985480e-01 1.4512712e-04 3.4858847e-15]\n",
      " [4.7190731e-16 4.6612245e-11 1.0000000e+00]\n",
      " [7.3835625e-05 9.9216193e-01 7.7642608e-03]\n",
      " [1.8530105e-06 9.9409616e-01 5.9019839e-03]]\n",
      "\n",
      "Predicted Classes: [1 0 2 1 1 0 1 2 1 1]\n",
      "Actual Classes:    [1 0 2 1 1 0 1 2 1 1]\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### ‚úÖ **Expected Output**\n",
    "\n",
    "```\n",
    "Epoch\n",
    "50 / 50\n",
    "...\n",
    "‚úÖ Test\n",
    "Accuracy: 0.966\n",
    "\n",
    "Predicted\n",
    "Classes: [0 1 2 1 0 2 2 1 0 1]\n",
    "Actual\n",
    "Classes: [0 1 2 1 0 2 2 1 0 1]\n",
    "```\n",
    "\n",
    "---"
   ],
   "id": "bbf09358837d243f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T01:15:04.709809Z",
     "start_time": "2025-11-24T01:15:04.702453Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "### visualize :(learning curve)\n",
    "\n",
    "* you can visualize how the model learns over epochs a **plot of the training vs validation accuracy / loss** (learning curve)\n"
   ],
   "id": "547459ee14bd8dce"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
